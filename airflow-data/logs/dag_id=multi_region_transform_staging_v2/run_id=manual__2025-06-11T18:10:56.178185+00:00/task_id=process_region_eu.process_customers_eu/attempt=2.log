[2025-06-11T18:18:17.791+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: multi_region_transform_staging_v2.process_region_eu.process_customers_eu manual__2025-06-11T18:10:56.178185+00:00 [queued]>
[2025-06-11T18:18:17.810+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: multi_region_transform_staging_v2.process_region_eu.process_customers_eu manual__2025-06-11T18:10:56.178185+00:00 [queued]>
[2025-06-11T18:18:17.811+0000] {taskinstance.py:2170} INFO - Starting attempt 2 of 2
[2025-06-11T18:18:17.843+0000] {taskinstance.py:2191} INFO - Executing <Task(_PythonDecoratedOperator): process_region_eu.process_customers_eu> on 2025-06-11 18:10:56.178185+00:00
[2025-06-11T18:18:17.861+0000] {standard_task_runner.py:60} INFO - Started process 266 to run task
[2025-06-11T18:18:17.867+0000] {standard_task_runner.py:87} INFO - Running: ['airflow', 'tasks', 'run', 'multi_region_transform_staging_v2', 'process_region_eu.process_customers_eu', 'manual__2025-06-11T18:10:56.178185+00:00', '--job-id', '599', '--raw', '--subdir', 'DAGS_FOLDER/master_dag.py', '--cfg-path', '/tmp/tmphto2md9x']
[2025-06-11T18:18:17.874+0000] {standard_task_runner.py:88} INFO - Job 599: Subtask process_region_eu.process_customers_eu
[2025-06-11T18:18:18.042+0000] {task_command.py:423} INFO - Running <TaskInstance: multi_region_transform_staging_v2.process_region_eu.process_customers_eu manual__2025-06-11T18:10:56.178185+00:00 [running]> on host 5950010ae7c1
[2025-06-11T18:18:18.395+0000] {taskinstance.py:2480} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='data-team' AIRFLOW_CTX_DAG_ID='multi_region_transform_staging_v2' AIRFLOW_CTX_TASK_ID='process_region_eu.process_customers_eu' AIRFLOW_CTX_EXECUTION_DATE='2025-06-11T18:10:56.178185+00:00' AIRFLOW_CTX_TRY_NUMBER='2' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-06-11T18:10:56.178185+00:00'
[2025-06-11T18:18:40.675+0000] {logging_mixin.py:188} INFO - Debugggg::::Vector(spark://5950010ae7c1:35103/jars/snowflake-jdbc-3.13.17.jar, spark://5950010ae7c1:35103/jars/spark-snowflake_2.12-2.16.0-spark_3.2.jar)
[2025-06-11T18:18:40.678+0000] {logging_mixin.py:188} INFO - Processing customers for region eu
[2025-06-11T18:18:40.728+0000] {logging_mixin.py:188} INFO - /opt/airflow/data/raw/region=eu/table=customers/load_date=2025-06-11
[2025-06-11T18:19:28.343+0000] {logging_mixin.py:188} INFO - STAGING_EU
[2025-06-11T18:19:37.643+0000] {logging_mixin.py:188} INFO - +-----------+--------------------+----------+---------+-----------------+------------+-------------------+----------+---------+----------------+-------------------+--------------------+-------------------+-------------------+-------------------+-------+--------+
|customer_id|               email|first_name|last_name|            phone|country_code|  registration_date|last_login|is_active|customer_segment|  gdpr_consent_date|data_retention_until|acquisition_channel|         created_at|         updated_at|_region| _source|
+-----------+--------------------+----------+---------+-----------------+------------+-------------------+----------+---------+----------------+-------------------+--------------------+-------------------+-------------------+-------------------+-------+--------+
|          1|55f537baf75630a85...|      J***|     D***| +49-***-***-5678|          DE|2025-06-11 02:14:31|      NULL|     true|         premium|2024-01-15 09:30:00| 2027-01-15 00:00:00|            organic|2025-06-11 02:14:31|2025-06-11 02:14:31|     eu|postgres|
|          2|8384b028d4f6ef2ac...|      M***|     G***| +34-***-***-4567|          ES|2025-06-11 02:14:31|      NULL|     true|        standard|2024-01-16 10:45:00| 2027-01-16 00:00:00|       social_media|2025-06-11 02:14:31|2025-06-11 02:14:31|     eu|postgres|
|          3|d9ff2965224667fd5...|      P***|     M***| +33-***-***-8901|          FR|2025-06-11 02:14:31|      NULL|     true|      enterprise|2024-01-17 08:20:00| 2027-01-17 00:00:00|           referral|2025-06-11 02:14:31|2025-06-11 02:14:31|     eu|postgres|
|          4|c797cfbb6e65ecf5d...|      A***|     R***| +39-***-***-4321|          IT|2025-06-11 02:14:31|      NULL|     true|        standard|2024-01-18 13:15:00| 2027-01-18 00:00:00|           paid_ads|2025-06-11 02:14:31|2025-06-11 02:14:31|     eu|postgres|
|          5|3e8f559f81c2fe033...|      L***|     N***| +45-***-***-3456|          DK|2025-06-11 02:14:31|      NULL|     true|         premium|2024-01-19 15:30:00| 2027-01-19 00:00:00|            organic|2025-06-11 02:14:31|2025-06-11 02:14:31|     eu|postgres|
|          6|                NULL|      S***|     D***| +33-***-***-7890|          FR|2025-06-11 02:14:31|      NULL|     true|        standard|2024-01-20 11:45:00| 2027-01-20 00:00:00|     email_campaign|2025-06-11 02:14:31|2025-06-11 02:14:31|     eu|postgres|
|          7|                NULL|      H***|     M***| +49-***-***-6543|          DE|2025-06-11 02:14:31|      NULL|     true|        standard|2024-01-21 07:30:00| 2027-01-21 00:00:00|            organic|2025-06-11 02:14:31|2025-06-11 02:14:31|     eu|postgres|
|          8|                NULL|      E***|     P***|+359-***-***-4567|          BG|2025-06-11 02:14:31|      NULL|     true|         premium|2024-01-22 14:20:00| 2027-01-22 00:00:00|           referral|2025-06-11 02:14:31|2025-06-11 02:14:31|     eu|postgres|
|          9|                NULL|      M***|     B***| +39-***-***-3344|          IT|2025-06-11 02:14:31|      NULL|     true|        standard|2024-01-23 10:10:00| 2027-01-23 00:00:00|       social_media|2025-06-11 02:14:31|2025-06-11 02:14:31|     eu|postgres|
|         10|                NULL|      I***|     L***| +46-***-***-6778|          SE|2025-06-11 02:14:31|      NULL|     true|      enterprise|2024-01-24 12:55:00| 2027-01-24 00:00:00|           paid_ads|2025-06-11 02:14:31|2025-06-11 02:14:31|     eu|postgres|
+-----------+--------------------+----------+---------+-----------------+------------+-------------------+----------+---------+----------------+-------------------+--------------------+-------------------+-------------------+-------------------+-------+--------+
only showing top 10 rows
[2025-06-11T18:19:37.646+0000] {logging_mixin.py:188} INFO - Inserting into snowflake
[2025-06-11T18:19:49.509+0000] {logging_mixin.py:188} INFO - successfully inserted in snowflake
[2025-06-11T18:19:49.600+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2025-06-11T18:19:50.519+0000] {logging_mixin.py:188} INFO - Successfully processed 25 records for customers in eu
[2025-06-11T18:19:51.030+0000] {local_task_job_runner.py:302} WARNING - State of this instance has been externally set to failed. Terminating instance.
[2025-06-11T18:19:51.122+0000] {process_utils.py:131} INFO - Sending 15 to group 266. PIDs of all processes in the group: [315, 1976, 2088, 266]
[2025-06-11T18:19:51.125+0000] {process_utils.py:86} INFO - Sending the signal 15 to group 266
[2025-06-11T18:19:51.128+0000] {taskinstance.py:2450} ERROR - Received SIGTERM. Terminating subprocesses.
[2025-06-11T18:19:51.132+0000] {clientserver.py:538} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.10/socket.py", line 705, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/taskinstance.py", line 2452, in signal_handler
    raise AirflowException("Task received SIGTERM signal")
airflow.exceptions.AirflowException: Task received SIGTERM signal
[2025-06-11T18:19:51.135+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2025-06-11T18:19:51.137+0000] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.10/socket.py", line 705, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/taskinstance.py", line 2452, in signal_handler
    raise AirflowException("Task received SIGTERM signal")
airflow.exceptions.AirflowException: Task received SIGTERM signal

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.10/site-packages/py4j/clientserver.py", line 539, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2025-06-11T18:19:51.138+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2025-06-11T18:19:51.196+0000] {logging_mixin.py:188} WARNING - /home/airflow/.local/lib/python3.10/site-packages/pyspark/context.py:657 RuntimeWarning: Unable to cleanly shutdown Spark JVM process. It is possible that the process has crashed, been killed or may also be in a zombie state.
[2025-06-11T18:19:51.539+0000] {clientserver.py:538} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.10/socket.py", line 705, in readinto
    return self._sock.recv_into(b)
ConnectionResetError: [Errno 104] Connection reset by peer
[2025-06-11T18:19:51.540+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2025-06-11T18:19:51.556+0000] {taskinstance.py:2698} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.10/socket.py", line 705, in readinto
    return self._sock.recv_into(b)
ConnectionResetError: [Errno 104] Connection reset by peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/taskinstance.py", line 433, in _execute_task
    result = execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/decorators/base.py", line 241, in execute
    return_value = super().execute(context)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/operators/python.py", line 199, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/operators/python.py", line 216, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/master_dag.py", line 305, in process_table
    spark.stop()
  File "/home/airflow/.local/lib/python3.10/site-packages/pyspark/sql/session.py", line 1799, in stop
    self._jvm.SparkSession.clearDefaultSession()
  File "/home/airflow/.local/lib/python3.10/site-packages/py4j/java_gateway.py", line 1712, in __getattr__
    answer = self._gateway_client.send_command(
  File "/home/airflow/.local/lib/python3.10/site-packages/py4j/java_gateway.py", line 1036, in send_command
    connection = self._get_connection()
  File "/home/airflow/.local/lib/python3.10/site-packages/py4j/clientserver.py", line 284, in _get_connection
    connection = self._create_new_connection()
  File "/home/airflow/.local/lib/python3.10/site-packages/py4j/clientserver.py", line 291, in _create_new_connection
    connection.connect_to_java_server()
  File "/home/airflow/.local/lib/python3.10/site-packages/py4j/clientserver.py", line 443, in connect_to_java_server
    self._authenticate_connection()
  File "/home/airflow/.local/lib/python3.10/site-packages/py4j/clientserver.py", line 459, in _authenticate_connection
    answer = self.send_command(cmd)
  File "/home/airflow/.local/lib/python3.10/site-packages/py4j/clientserver.py", line 539, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2025-06-11T18:19:51.616+0000] {taskinstance.py:1138} INFO - Marking task as FAILED. dag_id=multi_region_transform_staging_v2, task_id=process_region_eu.process_customers_eu, execution_date=20250611T181056, start_date=20250611T181817, end_date=20250611T181951
[2025-06-11T18:19:51.706+0000] {standard_task_runner.py:107} ERROR - Failed to execute job 599 for task process_region_eu.process_customers_eu (Error while sending or receiving; 266)
[2025-06-11T18:19:51.724+0000] {process_utils.py:79} INFO - Process psutil.Process(pid=315, status='terminated', started='18:18:18') (315) terminated with exit code None
[2025-06-11T18:19:51.725+0000] {process_utils.py:79} INFO - Process psutil.Process(pid=1976, status='terminated', started='18:19:33') (1976) terminated with exit code None
[2025-06-11T18:19:51.726+0000] {process_utils.py:79} INFO - Process psutil.Process(pid=2088, status='terminated', started='18:19:43') (2088) terminated with exit code None
[2025-06-11T18:19:51.726+0000] {process_utils.py:79} INFO - Process psutil.Process(pid=266, status='terminated', exitcode=1, started='18:18:17') (266) terminated with exit code 1
