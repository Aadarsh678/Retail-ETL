[2025-06-03T07:13:00.132+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: ingest_raw_data_asia.extract_asia_asia_orders manual__2025-06-03T06:07:18.020901+00:00 [queued]>
[2025-06-03T07:13:05.619+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: ingest_raw_data_asia.extract_asia_asia_orders manual__2025-06-03T06:07:18.020901+00:00 [queued]>
[2025-06-03T07:13:05.620+0000] {taskinstance.py:2170} INFO - Starting attempt 1 of 2
[2025-06-03T07:13:09.465+0000] {taskinstance.py:2191} INFO - Executing <Task(BashOperator): extract_asia_asia_orders> on 2025-06-03 06:07:18.020901+00:00
[2025-06-03T07:13:09.469+0000] {standard_task_runner.py:60} INFO - Started process 3043 to run task
[2025-06-03T07:13:09.662+0000] {standard_task_runner.py:87} INFO - Running: ['airflow', 'tasks', 'run', 'ingest_raw_data_asia', 'extract_asia_asia_orders', 'manual__2025-06-03T06:07:18.020901+00:00', '--job-id', '257', '--raw', '--subdir', 'DAGS_FOLDER/asia/landing.py', '--cfg-path', '/tmp/tmpr23dmlzv']
[2025-06-03T07:13:09.663+0000] {standard_task_runner.py:88} INFO - Job 257: Subtask extract_asia_asia_orders
[2025-06-03T07:13:09.743+0000] {logging_mixin.py:188} WARNING - /home/airflow/.local/lib/python3.10/site-packages/airflow/settings.py:194 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-06-03T07:13:09.774+0000] {task_command.py:423} INFO - Running <TaskInstance: ingest_raw_data_asia.extract_asia_asia_orders manual__2025-06-03T06:07:18.020901+00:00 [running]> on host 86069ee61878
[2025-06-03T07:13:16.277+0000] {taskinstance.py:2480} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='ingest_raw_data_asia' AIRFLOW_CTX_TASK_ID='extract_asia_asia_orders' AIRFLOW_CTX_EXECUTION_DATE='2025-06-03T06:07:18.020901+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-06-03T06:07:18.020901+00:00'
[2025-06-03T07:13:16.440+0000] {subprocess.py:63} INFO - Tmp dir root location: /tmp
[2025-06-03T07:13:16.646+0000] {subprocess.py:75} INFO - Running command: ['/usr/bin/bash', '-c', '\n                spark-submit                     /opt/airflow/scripts/pyspark_jobs/extract_to_parquet.py                     asia.orders "jdbc:postgresql://retail-postgres:5432/retail_etl" retail-etl retail_etl 2025-06-03\n            ']
[2025-06-03T07:13:16.911+0000] {subprocess.py:86} INFO - Output:
[2025-06-03T07:14:06.845+0000] {subprocess.py:93} INFO - 25/06/03 07:14:06 INFO SparkContext: Running Spark version 3.5.6
[2025-06-03T07:14:06.977+0000] {subprocess.py:93} INFO - 25/06/03 07:14:06 INFO SparkContext: OS info Linux, 6.11.0-26-generic, amd64
[2025-06-03T07:14:06.977+0000] {subprocess.py:93} INFO - 25/06/03 07:14:06 INFO SparkContext: Java version 11.0.24
[2025-06-03T07:14:07.196+0000] {subprocess.py:93} INFO - 25/06/03 07:14:07 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[2025-06-03T07:14:07.638+0000] {subprocess.py:93} INFO - 25/06/03 07:14:07 INFO ResourceUtils: ==============================================================
[2025-06-03T07:14:07.639+0000] {subprocess.py:93} INFO - 25/06/03 07:14:07 INFO ResourceUtils: No custom resources configured for spark.driver.
[2025-06-03T07:14:07.643+0000] {subprocess.py:93} INFO - 25/06/03 07:14:07 INFO ResourceUtils: ==============================================================
[2025-06-03T07:14:07.644+0000] {subprocess.py:93} INFO - 25/06/03 07:14:07 INFO SparkContext: Submitted application: Extract_asia_asia.orders
[2025-06-03T07:14:07.719+0000] {subprocess.py:93} INFO - 25/06/03 07:14:07 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
[2025-06-03T07:14:07.783+0000] {subprocess.py:93} INFO - 25/06/03 07:14:07 INFO ResourceProfile: Limiting resource is cpu
[2025-06-03T07:14:07.786+0000] {subprocess.py:93} INFO - 25/06/03 07:14:07 INFO ResourceProfileManager: Added ResourceProfile id: 0
[2025-06-03T07:14:15.127+0000] {subprocess.py:93} INFO - 25/06/03 07:14:15 INFO SecurityManager: Changing view acls to: airflow
[2025-06-03T07:14:15.202+0000] {subprocess.py:93} INFO - 25/06/03 07:14:15 INFO SecurityManager: Changing modify acls to: airflow
[2025-06-03T07:14:15.202+0000] {subprocess.py:93} INFO - 25/06/03 07:14:15 INFO SecurityManager: Changing view acls groups to:
[2025-06-03T07:14:15.202+0000] {subprocess.py:93} INFO - 25/06/03 07:14:15 INFO SecurityManager: Changing modify acls groups to:
[2025-06-03T07:14:15.202+0000] {subprocess.py:93} INFO - 25/06/03 07:14:15 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow; groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY
[2025-06-03T07:14:33.539+0000] {subprocess.py:93} INFO - 25/06/03 07:14:33 INFO Utils: Successfully started service 'sparkDriver' on port 39967.
[2025-06-03T07:14:38.103+0000] {subprocess.py:93} INFO - 25/06/03 07:14:38 INFO SparkEnv: Registering MapOutputTracker
[2025-06-03T07:14:39.160+0000] {subprocess.py:93} INFO - 25/06/03 07:14:39 INFO SparkEnv: Registering BlockManagerMaster
[2025-06-03T07:14:39.295+0000] {subprocess.py:93} INFO - 25/06/03 07:14:39 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[2025-06-03T07:14:39.296+0000] {subprocess.py:93} INFO - 25/06/03 07:14:39 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
[2025-06-03T07:14:39.306+0000] {subprocess.py:93} INFO - 25/06/03 07:14:39 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
[2025-06-03T07:14:40.161+0000] {subprocess.py:93} INFO - 25/06/03 07:14:40 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-2530f525-81db-4e13-a9d1-fa6620b2c92c
[2025-06-03T07:14:42.278+0000] {subprocess.py:93} INFO - 25/06/03 07:14:42 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
[2025-06-03T07:14:46.591+0000] {subprocess.py:93} INFO - 25/06/03 07:14:46 INFO SparkEnv: Registering OutputCommitCoordinator
[2025-06-03T07:15:06.589+0000] {subprocess.py:93} INFO - 25/06/03 07:15:06 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
[2025-06-03T07:15:09.280+0000] {subprocess.py:93} INFO - 25/06/03 07:15:09 INFO Utils: Successfully started service 'SparkUI' on port 4040.
[2025-06-03T07:15:16.597+0000] {subprocess.py:93} INFO - 25/06/03 07:15:16 INFO Executor: Starting executor ID driver on host 86069ee61878
[2025-06-03T07:15:16.602+0000] {subprocess.py:93} INFO - 25/06/03 07:15:16 INFO Executor: OS info Linux, 6.11.0-26-generic, amd64
[2025-06-03T07:15:16.603+0000] {subprocess.py:93} INFO - 25/06/03 07:15:16 INFO Executor: Java version 11.0.24
[2025-06-03T07:15:17.043+0000] {subprocess.py:93} INFO - 25/06/03 07:15:17 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
[2025-06-03T07:15:17.045+0000] {subprocess.py:93} INFO - 25/06/03 07:15:17 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@77722976 for default.
[2025-06-03T07:15:18.104+0000] {subprocess.py:93} INFO - 25/06/03 07:15:18 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35737.
[2025-06-03T07:15:18.282+0000] {subprocess.py:93} INFO - 25/06/03 07:15:18 INFO NettyBlockTransferService: Server created on 86069ee61878:35737
[2025-06-03T07:15:18.514+0000] {subprocess.py:93} INFO - 25/06/03 07:15:18 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[2025-06-03T07:15:19.205+0000] {subprocess.py:93} INFO - 25/06/03 07:15:19 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 86069ee61878, 35737, None)
[2025-06-03T07:15:19.487+0000] {subprocess.py:93} INFO - 25/06/03 07:15:19 INFO BlockManagerMasterEndpoint: Registering block manager 86069ee61878:35737 with 434.4 MiB RAM, BlockManagerId(driver, 86069ee61878, 35737, None)
[2025-06-03T07:15:19.790+0000] {subprocess.py:93} INFO - 25/06/03 07:15:19 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 86069ee61878, 35737, None)
[2025-06-03T07:15:19.791+0000] {subprocess.py:93} INFO - 25/06/03 07:15:19 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 86069ee61878, 35737, None)
[2025-06-03T07:15:26.823+0000] {subprocess.py:93} INFO - 25/06/03 07:15:26 INFO AsyncEventQueue: Process of event SparkListenerResourceProfileAdded(Profile: id = 0, executor resources: cores -> name: cores, amount: 1, script: , vendor: ,memory -> name: memory, amount: 1024, script: , vendor: ,offHeap -> name: offHeap, amount: 0, script: , vendor: , task resources: cpus -> name: cpus, amount: 1.0) by listener HeartbeatReceiver took 1.640165202s.
[2025-06-03T07:15:26.824+0000] {subprocess.py:93} INFO - 25/06/03 07:15:26 INFO AsyncEventQueue: Process of event SparkListenerResourceProfileAdded(Profile: id = 0, executor resources: cores -> name: cores, amount: 1, script: , vendor: ,memory -> name: memory, amount: 1024, script: , vendor: ,offHeap -> name: offHeap, amount: 0, script: , vendor: , task resources: cpus -> name: cpus, amount: 1.0) by listener AppStatusListener took 1.645596592s.
[2025-06-03T07:15:32.891+0000] {subprocess.py:93} INFO - 25/06/03 07:15:32 INFO AsyncEventQueue: Process of event SparkListenerExecutorAdded(1748934917542,driver,org.apache.spark.scheduler.cluster.ExecutorInfo@91197beb) by listener AppStatusListener took 3.825169365s.
[2025-06-03T07:15:36.137+0000] {subprocess.py:93} INFO - 25/06/03 07:15:36 INFO AsyncEventQueue: Process of event SparkListenerBlockManagerAdded(1748934919484,BlockManagerId(driver, 86069ee61878, 35737, None),455501414,Some(455501414),Some(0)) by listener AppStatusListener took 3.245841802s.
[2025-06-03T07:15:46.237+0000] {subprocess.py:93} INFO - 25/06/03 07:15:45 INFO AsyncEventQueue: Process of event SparkListenerEnvironmentUpdate(Map(Spark Properties -> ArrayBuffer((spark.app.id,local-1748934913853), (spark.app.name,Extract_asia_asia.orders), (spark.app.startTime,1748934846511), (spark.app.submitTime,1748934843625), (spark.driver.extraJavaOptions,-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false), (spark.driver.host,86069ee61878), (spark.driver.port,39967), (spark.executor.extraJavaOptions,-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false), (spark.executor.id,driver), (spark.master,local[*]), (spark.rdd.compress,True), (spark.scheduler.mode,FIFO), (spark.serializer.objectStreamReset,100), (spark.submit.deployMode,client), (spark.submit.pyFiles,)), Classpath Entries -> Vector((/usr/local/spark/conf/,System Classpath), (/usr/local/spark/jars/HikariCP-2.5.1.jar,System Classpath), (/usr/local/spark/jars/JLargeArrays-1.5.jar,System Classpath), (/usr/local/spark/jars/JTransforms-3.1.jar,System Classpath), (/usr/local/spark/jars/RoaringBitmap-0.9.45.jar,System Classpath), (/usr/local/spark/jars/ST4-4.0.4.jar,System Classpath), (/usr/local/spark/jars/activation-1.1.1.jar,System Classpath), (/usr/local/spark/jars/aircompressor-0.27.jar,System Classpath), (/usr/local/spark/jars/algebra_2.12-2.0.1.jar,System Classpath), (/usr/local/spark/jars/annotations-17.0.0.jar,System Classpath), (/usr/local/spark/jars/antlr-runtime-3.5.2.jar,System Classpath), (/usr/local/spark/jars/antlr4-runtime-4.9.3.jar,System Classpath), (/usr/local/spark/jars/aopalliance-repackaged-2.6.1.jar,System Classpath), (/usr/local/spark/jars/arpack-3.0.3.jar,System Classpath), (/usr/local/spark/jars/arpack_combined_all-0.1.jar,System Classpath), (/usr/local/spark/jars/arrow-format-12.0.1.jar,System Classpath), (/usr/local/spark/jars/arrow-memory-core-12.0.1.jar,System Classpath), (/usr/local/spark/jars/arrow-memory-netty-12.0.1.jar,System Classpath), (/usr/local/spark/jars/arrow-vector-12.0.1.jar,System Classpath), (/usr/local/spark/jars/audience-annotations-0.5.0.jar,System Classpath), (/usr/local/spark/jars/avro-1.11.4.jar,System Classpath), (/usr/local/spark/jars/avro-ipc-1.11.4.jar,System Classpath), (/usr/local/spark/jars/avro-mapred-1.11.4.jar,System Classpath), (/usr/local/spark/jars/blas-3.0.3.jar,System Classpath), (/usr/local/spark/jars/bonecp-0.8.0.RELEASE.jar,System Classpath), (/usr/local/spark/jars/breeze-macros_2.12-2.1.0.jar,System Classpath), (/usr/local/spark/jars/breeze_2.12-2.1.0.jar,System Classpath), (/usr/local/spark/jars/cats-kernel_2.12-2.1.1.jar,System Classpath), (/usr/local/spark/jars/chill-java-0.10.0.jar,System Classpath), (/usr/local/spark/jars/chill_2.12-0.10.0.jar,System Classpath), (/usr/local/spark/jars/commons-cli-1.5.0.jar,System Classpath), (/usr/local/spark/jars/commons-codec-1.16.1.jar,System Classpath), (/usr/local/spark/jars/commons-collections-3.2.2.jar,System Classpath), (/usr/local/spark/jars/commons-collections4-4.4.jar,System Classpath), (/usr/local/spark/jars/commons-compiler-3.1.9.jar,System Classpath), (/usr/local/spark/jars/commons-compress-1.23.0.jar,System Classpath), (/usr/local/spark/jars/commons-crypto-1.1.0.jar,System Classpath), (/usr/local/spark/jars/commons-dbcp-1.4.jar,System Classpath), (/usr/local/spark/jars/commons-io-2.16.1.jar,System Classpath), (/usr/local/spark/jars/commons-lang-2.6.jar,System Classpath), (/usr/local/spark/jars/commons-lang3-3.12.0.jar,System Classpath), (/usr/local/spark/jars/commons-logging-1.1.3.jar,System Classpath), (/usr/local/spark/jars/commons-math3-3.6.1.jar,System Classpath), (/usr/local/spark/jars/commons-pool-1.5.4.jar,System Classpath), (/usr/local/spark/jars/commons-text-1.10.0.jar,System Classpath), (/usr/local/spark/jars/compress-lzf-1.1.2.jar,System Classpath), (/usr/local/spark/jars/curator-client-2.13.0.jar,System Classpath), (/usr/local/spark/jars/curator-framework-2.13.0.jar,System Classpath), (/usr/local/spark/jars/curator-recipes-2.13.0.jar,System Classpath), (/usr/local/spark/jars/datanucleus-api-jdo-4.2.4.jar,System Classpath), (/usr/local/spark/jars/datanucleus-core-4.1.17.jar,System Classpath), (/usr/local/spark/jars/datanucleus-rdbms-4.1.19.jar,System Classpath), (/usr/local/spark/jars/datasketches-java-3.3.0.jar,System Classpath), (/usr/local/spark/jars/datasketches-memory-2.1.0.jar,System Classpath), (/usr/local/spark/jars/derby-10.14.2.0.jar,System Classpath), (/usr/local/spark/jars/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar,System Classpath), (/usr/local/spark/jars/flatbuffers-java-1.12.0.jar,System Classpath), (/usr/local/spark/jars/gson-2.2.4.jar,System Classpath), (/usr/local/spark/jars/guava-14.0.1.jar,System Classpath), (/usr/local/spark/jars/hadoop-client-api-3.3.4.jar,System Classpath), (/usr/local/spark/jars/hadoop-client-runtime-3.3.4.jar,System Classpath), (/usr/local/spark/jars/hadoop-shaded-guava-1.1.1.jar,System Classpath), (/usr/local/spark/jars/hadoop-yarn-server-web-proxy-3.3.4.jar,System Classpath), (/usr/local/spark/jars/hive-beeline-2.3.9.jar,System Classpath), (/usr/local/spark/jars/hive-cli-2.3.9.jar,System Classpath), (/usr/local/spark/jars/hive-common-2.3.9.jar,System Classpath), (/usr/local/spark/jars/hive-exec-2.3.9-core.jar,System Classpath), (/usr/local/spark/jars/hive-jdbc-2.3.9.jar,System Classpath), (/usr/local/spark/jars/hive-llap-common-2.3.9.jar,System Classpath), (/usr/local/spark/jars/hive-metastore-2.3.9.jar,System Classpath), (/usr/local/spark/jars/hive-serde-2.3.9.jar,System Classpath), (/usr/local/spark/jars/hive-service-rpc-3.1.3.jar,System Classpath), (/usr/local/spark/jars/hive-shims-0.23-2.3.9.jar,System Classpath), (/usr/local/spark/jars/hive-shims-2.3.9.jar,System Classpath), (/usr/local/spark/jars/hive-shims-common-2.3.9.jar,System Classpath), (/usr/local/spark/jars/hive-shims-scheduler-2.3.9.jar,System Classpath), (/usr/local/spark/jars/hive-storage-api-2.8.1.jar,System Classpath), (/usr/local/spark/jars/hk2-api-2.6.1.jar,System Classpath), (/usr/local/spark/jars/hk2-locator-2.6.1.jar,System Classpath), (/usr/local/spark/jars/hk2-utils-2.6.1.jar,System Classpath), (/usr/local/spark/jars/httpclient-4.5.14.jar,System Classpath), (/usr/local/spark/jars/httpcore-4.4.16.jar,System Classpath), (/usr/local/spark/jars/istack-commons-runtime-3.0.8.jar,System Classpath), (/usr/local/spark/jars/ivy-2.5.1.jar,System Classpath), (/usr/local/spark/jars/jackson-annotations-2.15.2.jar,System Classpath), (/usr/local/spark/jars/jackson-core-2.15.2.jar,System Classpath), (/usr/local/spark/jars/jackson-core-asl-1.9.13.jar,System Classpath), (/usr/local/spark/jars/jackson-databind-2.15.2.jar,System Classpath), (/usr/local/spark/jars/jackson-dataformat-yaml-2.15.2.jar,System Classpath), (/usr/local/spark/jars/jackson-datatype-jsr310-2.15.2.jar,System Classpath), (/usr/local/spark/jars/jackson-mapper-asl-1.9.13.jar,System Classpath), (/usr/local/spark/jars/jackson-module-scala_2.12-2.15.2.jar,System Classpath), (/usr/local/spark/jars/jakarta.annotation-api-1.3.5.jar,System Classpath), (/usr/local/spark/jars/jakarta.inject-2.6.1.jar,System Classpath), (/usr/local/spark/jars/jakarta.servlet-api-4.0.3.jar,System Classpath), (/usr/local/spark/jars/jakarta.validation-api-2.0.2.jar,System Classpath), (/usr/local/spark/jars/jakarta.ws.rs-api-2.1.6.jar,System Classpath), (/usr/local/spark/jars/jakarta.xml.bind-api-2.3.2.jar,System Classpath), (/usr/local/spark/jars/janino-3.1.9.jar,System Classpath), (/usr/local/spark/jars/javassist-3.29.2-GA.jar,System Classpath), (/usr/local/spark/jars/javax.jdo-3.2.0-m3.jar,System Classpath), (/usr/local/spark/jars/javolution-5.5.1.jar,System Classpath), (/usr/local/spark/jars/jaxb-runtime-2.3.2.jar,System Classpath), (/usr/local/spark/jars/jcl-over-slf4j-2.0.7.jar,System Classpath), (/usr/local/spark/jars/jdo-api-3.0.1.jar,System Classpath), (/usr/local/spark/jars/jersey-client-2.40.jar,System Classpath), (/usr/local/spark/jars/jersey-common-2.40.jar,System Classpath), (/usr/local/spark/jars/jersey-container-servlet-2.40.jar,System Classpath), (/usr/local/spark/jars/jersey-container-servlet-core-2.40.jar,System Classpath), (/usr/local/spark/jars/jersey-hk2-2.40.jar,System Classpath), (/usr/local/spark/jars/jersey-server-2.40.jar,System Classpath), (/usr/local/spark/jars/jline-2.14.6.jar,System Classpath), (/usr/local/spark/jars/joda-time-2.12.5.jar,System Classpath), (/usr/local/spark/jars/jodd-core-3.5.2.jar,System Classpath), (/usr/local/spark/jars/jpam-1.1.jar,System Classpath), (/usr/local/spark/jars/json-1.8.jar,System Classpath), (/usr/local/spark/jars/json4s-ast_2.12-3.7.0-M11.jar,System Classpath), (/usr/local/spark/jars/json4s-core_2.12-3.7.0-M11.jar,System Classpath), (/usr/local/spark/jars/json4s-jackson_2.12-3.7.0-M11.jar,System Classpath), (/usr/local/spark/jars/json4s-scalap_2.12-3.7.0-M11.jar,System Classpath), (/usr/local/spark/jars/jsr305-3.0.0.jar,System Classpath), (/usr/local/spark/jars/jta-1.1.jar,System Classpath), (/usr/local/spark/jars/jul-to-slf4j-2.0.7.jar,System Classpath), (/usr/local/spark/jars/kryo-shaded-4.0.2.jar,System Classpath), (/usr/local/spark/jars/kubernetes-client-6.7.2.jar,System Classpath), (/usr/local/spark/jars/kubernetes-client-api-6.7.2.jar,System Classpath), (/usr/local/spark/jars/kubernetes-httpclient-okhttp-6.7.2.jar,System Classpath), (/usr/local/spark/jars/kubernetes-model-admissionregistration-6.7.2.jar,System Classpath), (/usr/local/spark/jars/kubernetes-model-apiextensions-6.7.2.jar,System Classpath), (/usr/local/spark/jars/kubernetes-model-apps-6.7.2.jar,System Classpath), (/usr/local/spark/jars/kubernetes-model-autoscaling-6.7.2.jar,System Classpath), (/usr/local/spark/jars/kubernetes-model-batch-6.7.2.jar,System Classpath), (/usr/local/spark/jars/kubernetes-model-certificates-6.7.2.jar,System Classpath), (/usr/local/spark/jars/kubernetes-model-common-6.7.2.jar,System Classpath), (/usr/local/spark/jars/kubernetes-model-coordination-6.7.2.jar,System Classpath), (/usr/local/spark/jars/kubernetes-model-core-6.7.2.jar,System Classpath), (/usr/local/spark/jars/kubernetes-model-discovery-6.7.2.jar,System Classpath), (/usr/local/spark/jars/kubernetes-model-events-6.7.2.jar,System Classpath), (/usr/local/spark/jars/kubernetes-model-extensions-6.7.2.jar,System Classpath), (/usr/local/spark/jars/kubernetes-model-flowcontrol-6.7.2.jar,System Classpath), (/usr/local/spark/jars/kubernetes-model-gatewayapi-6.7.2.jar,System Classpath), (/usr/local/spark/jars/kubernetes-model-metrics-6.7.2.jar,System Classpath), (/usr/local/spark/jars/kubernetes-model-networking-6.7.2.jar,System Classpath), (/usr/local/spark/jars/kubernetes-model-node-6.7.2.jar,System Classpath), (/usr/local/spark/jars/kubernetes-model-policy-6.7.2.jar,System Classpath), (/usr/local/spark/jars/kubernetes-model-rbac-6.7.2.jar,System Classpath), (/usr/local/spark/jars/kubernetes-model-resource-6.7.2.jar,System Classpath), (/usr/local/spark/jars/kubernetes-model-scheduling-6.7.2.jar,System Classpath), (/usr/local/spark/jars/kubernetes-model-storageclass-6.7.2.jar,System Classpath), (/usr/local/spark/jars/lapack-3.0.3.jar,System Classpath), (/usr/local/spark/jars/leveldbjni-all-1.8.jar,System Classpath), (/usr/local/spark/jars/libfb303-0.9.3.jar,System Classpath), (/usr/local/spark/jars/libthrift-0.12.0.jar,System Classpath), (/usr/local/spark/jars/log4j-1.2-api-2.20.0.jar,System Classpath), (/usr/local/spark/jars/log4j-api-2.20.0.jar,System Classpath), (/usr/local/spark/jars/log4j-core-2.20.0.jar,System Classpath), (/usr/local/spark/jars/log4j-slf4j2-impl-2.20.0.jar,System Classpath), (/usr/local/spark/jars/logging-interceptor-3.12.12.jar,System Classpath), (/usr/local/spark/jars/lz4-java-1.8.0.jar,System Classpath), (/usr/local/spark/jars/mesos-1.4.3-shaded-protobuf.jar,System Classpath), (/usr/local/spark/jars/metrics-core-4.2.19.jar,System Classpath), (/usr/local/spark/jars/metrics-graphite-4.2.19.jar,System Classpath), (/usr/local/spark/jars/metrics-jmx-4.2.19.jar,System Classpath), (/usr/local/spark/jars/metrics-json-4.2.19.jar,System Classpath), (/usr/local/spark/jars/metrics-jvm-4.2.19.jar,System Classpath), (/usr/local/spark/jars/minlog-1.3.0.jar,System Classpath), (/usr/local/spark/jars/netty-all-4.1.96.Final.jar,System Classpath), (/usr/local/spark/jars/netty-buffer-4.1.96.Final.jar,System Classpath), (/usr/local/spark/jars/netty-codec-4.1.96.Final.jar,System Classpath), (/usr/local/spark/jars/netty-codec-http-4.1.96.Final.jar,System Classpath), (/usr/local/spark/jars/netty-codec-http2-4.1.96.Final.jar,System Classpath), (/usr/local/spark/jars/netty-codec-socks-4.1.96.Final.jar,System Classpath), (/usr/local/spark/jars/netty-common-4.1.96.Final.jar,System Classpath), (/usr/local/spark/jars/netty-handler-4.1.96.Final.jar,System Classpath), (/usr/local/spark/jars/netty-handler-proxy-4.1.96.Final.jar,System Classpath), (/usr/local/spark/jars/netty-resolver-4.1.96.Final.jar,System Classpath), (/usr/local/spark/jars/netty-transport-4.1.96.Final.jar,System Classpath), (/usr/local/spark/jars/netty-transport-classes-epoll-4.1.96.Final.jar,System Classpath), (/usr/local/spark/jars/netty-transport-classes-kqueue-4.1.96.Final.jar,System Classpath), (/usr/local/spark/jars/netty-transport-native-epoll-4.1.96.Final-linux-aarch_64.jar,System Classpath), (/usr/local/spark/jars/netty-transport-native-epoll-4.1.96.Final-linux-x86_64.jar,System Classpath), (/usr/local/spark/jars/netty-transport-native-kqueue-4.1.96.Final-osx-aarch_64.jar,System Classpath), (/usr/local/spark/jars/netty-transport-native-kqueue-4.1.96.Final-osx-x86_64.jar,System Classpath), (/usr/local/spark/jars/netty-transport-native-unix-common-4.1.96.Final.jar,System Classpath), (/usr/local/spark/jars/objenesis-3.3.jar,System Classpath), (/usr/local/spark/jars/okhttp-3.12.12.jar,System Classpath), (/usr/local/spark/jars/okio-1.17.6.jar,System Classpath), (/usr/local/spark/jars/opencsv-2.3.jar,System Classpath), (/usr/local/spark/jars/orc-core-1.9.6-shaded-protobuf.jar,System Classpath), (/usr/local/spark/jars/orc-mapreduce-1.9.6-shaded-protobuf.jar,System Classpath), (/usr/local/spark/jars/orc-shims-1.9.6.jar,System Classpath), (/usr/local/spark/jars/oro-2.0.8.jar,System Classpath), (/usr/local/spark/jars/osgi-resource-locator-1.0.3.jar,System Classpath), (/usr/local/spark/jars/paranamer-2.8.jar,System Classpath), (/usr/local/spark/jars/parquet-column-1.13.1.jar,System Classpath), (/usr/local/spark/jars/parquet-common-1.13.1.jar,System Classpath), (/usr/local/spark/jars/parquet-encoding-1.13.1.jar,System Classpath), (/usr/local/spark/jars/parquet-format-structures-1.13.1.jar,System Classpath), (/usr/local/spark/jars/parquet-hadoop-1.13.1.jar,System Classpath), (/usr/local/spark/jars/parquet-jackson-1.13.1.jar,System Classpath), (/usr/local/spark/jars/pickle-1.3.jar,System Classpath), (/usr/local/spark/jars/py4j-0.10.9.7.jar,System Classpath), (/usr/local/spark/jars/rocksdbjni-8.3.2.jar,System Classpath), (/usr/local/spark/jars/scala-collection-compat_2.12-2.7.0.jar,System Classpath), (/usr/local/spark/jars/scala-compiler-2.12.18.jar,System Classpath), (/usr/local/spark/jars/scala-library-2.12.18.jar,System Classpath), (/usr/local/spark/jars/scala-parser-combinators_2.12-2.3.0.jar,System Classpath), (/usr/local/spark/jars/scala-reflect-2.12.18.jar,System Classpath), (/usr/local/spark/jars/scala-xml_2.12-2.1.0.jar,System Classpath), (/usr/local/spark/jars/shims-0.9.45.jar,System Classpath), (/usr/local/spark/jars/slf4j-api-2.0.7.jar,System Classpath), (/usr/local/spark/jars/snakeyaml-2.0.jar,System Classpath), (/usr/local/spark/jars/snakeyaml-engine-2.6.jar,System Classpath), (/usr/local/spark/jars/snappy-java-1.1.10.5.jar,System Classpath), (/usr/local/spark/jars/spark-catalyst_2.12-3.5.6.jar,System Classpath), (/usr/local/spark/jars/spark-common-utils_2.12-3.5.6.jar,System Classpath), (/usr/local/spark/jars/spark-core_2.12-3.5.6.jar,System Classpath), (/usr/local/spark/jars/spark-graphx_2.12-3.5.6.jar,System Classpath), (/usr/local/spark/jars/spark-hive-thriftserver_2.12-3.5.6.jar,System Classpath), (/usr/local/spark/jars/spark-hive_2.12-3.5.6.jar,System Classpath), (/usr/local/spark/jars/spark-kubernetes_2.12-3.5.6.jar,System Classpath), (/usr/local/spark/jars/spark-kvstore_2.12-3.5.6.jar,System Classpath), (/usr/local/spark/jars/spark-launcher_2.12-3.5.6.jar,System Classpath), (/usr/local/spark/jars/spark-mesos_2.12-3.5.6.jar,System Classpath), (/usr/local/spark/jars/spark-mllib-local_2.12-3.5.6.jar,System Classpath), (/usr/local/spark/jars/spark-mllib_2.12-3.5.6.jar,System Classpath), (/usr/local/spark/jars/spark-network-common_2.12-3.5.6.jar,System Classpath), (/usr/local/spark/jars/spark-network-shuffle_2.12-3.5.6.jar,System Classpath), (/usr/local/spark/jars/spark-repl_2.12-3.5.6.jar,System Classpath), (/usr/local/spark/jars/spark-sketch_2.12-3.5.6.jar,System Classpath), (/usr/local/spark/jars/spark-sql-api_2.12-3.5.6.jar,System Classpath), (/usr/local/spark/jars/spark-sql_2.12-3.5.6.jar,System Classpath), (/usr/local/spark/jars/spark-streaming_2.12-3.5.6.jar,System Classpath), (/usr/local/spark/jars/spark-tags_2.12-3.5.6.jar,System Classpath), (/usr/local/spark/jars/spark-unsafe_2.12-3.5.6.jar,System Classpath), (/usr/local/spark/jars/spark-yarn_2.12-3.5.6.jar,System Classpath), (/usr/local/spark/jars/spire-macros_2.12-0.17.0.jar,System Classpath), (/usr/local/spark/jars/spire-platform_2.12-0.17.0.jar,System Classpath), (/usr/local/spark/jars/spire-util_2.12-0.17.0.jar,System Classpath), (/usr/local/spark/jars/spire_2.12-0.17.0.jar,System Classpath), (/usr/local/spark/jars/stax-api-1.0.1.jar,System Classpath), (/usr/local/spark/jars/stream-2.9.6.jar,System Classpath), (/usr/local/spark/jars/super-csv-2.2.0.jar,System Classpath), (/usr/local/spark/jars/threeten-extra-1.7.1.jar,System Classpath), (/usr/local/spark/jars/tink-1.9.0.jar,System Classpath), (/usr/local/spark/jars/transaction-api-1.1.jar,System Classpath), (/usr/local/spark/jars/univocity-parsers-2.9.1.jar,System Classpath), (/usr/local/spark/jars/xbean-asm9-shaded-4.23.jar,System Classpath), (/usr/local/spark/jars/xz-1.9.jar,System Classpath), (/usr/local/spark/jars/zjsonpatch-0.3.0.jar,System Classpath), (/usr/local/spark/jars/zookeeper-3.6.3.jar,System Classpath), (/usr/local/spark/jars/zookeeper-jute-3.6.3.jar,System Classpath), (/usr/local/spark/jars/zstd-jni-1.5.5-4.jar,System Classpath)), Hadoop Properties -> List((adl.feature.ownerandgroup.enableupn,false), (adl.http.timeout,-1), (dfs.client.ignore.namenode.default.kms.uri,false), (dfs.ha.fencing.ssh.connect-timeout,30000), (file.blocksize,67108864), (file.bytes-per-checksum,512), (file.client-write-packet-size,65536), (file.replication,1), (file.stream-buffer-size,4096), (fs.AbstractFileSystem.abfs.impl,org.apache.hadoop.fs.azurebfs.Abfs), (fs.AbstractFileSystem.abfss.impl,org.apache.hadoop.fs.azurebfs.Abfss), (fs.AbstractFileSystem.adl.impl,org.apache.hadoop.fs.adl.Adl), (fs.AbstractFileSystem.file.impl,org.apache.hadoop.fs.local.LocalFs), (fs.AbstractFileSystem.ftp.impl,org.apache.hadoop.fs.ftp.FtpFs), (fs.AbstractFileSystem.gs.impl,com.google.cloud.hadoop.fs.gcs.GoogleHadoopFS), (fs.AbstractFileSystem.har.impl,org.apache.hadoop.fs.HarFs), (fs.AbstractFileSystem.hdfs.impl,org.apache.hadoop.fs.Hdfs), (fs.AbstractFileSystem.s3a.impl,org.apache.hadoop.fs.s3a.S3A), (fs.AbstractFileSystem.swebhdfs.impl,org.apache.hadoop.fs.SWebHdfs), (fs.AbstractFileSystem.viewfs.impl,org.apache.hadoop.fs.viewfs.ViewFs), (fs.AbstractFileSystem.wasb.impl,org.apache.hadoop.fs.azure.Wasb), (fs.AbstractFileSystem.wasbs.impl,org.apache.hadoop.fs.azure.Wasbs), (fs.AbstractFileSystem.webhdfs.impl,org.apache.hadoop.fs.WebHdfs), (fs.abfs.impl,org.apache.hadoop.fs.azurebfs.AzureBlobFileSystem), (fs.abfss.impl,org.apache.hadoop.fs.azurebfs.SecureAzureBlobFileSystem), (fs.adl.impl,org.apache.hadoop.fs.adl.AdlFileSystem), (fs.adl.oauth2.access.token.provider.type,*********(redacted)), (fs.automatic.close,true), (fs.azure.authorization,false), (fs.azure.authorization.caching.enable,true), (fs.azure.buffer.dir,${hadoop.tmp.dir}/abfs), (fs.azure.local.sas.key.mode,false), (fs.azure.sas.expiry.period,90d), (fs.azure.saskey.usecontainersaskeyforallaccess,true), (fs.azure.secure.mode,false), (fs.azure.user.agent.prefix,unknown), (fs.client.resolve.remote.symlinks,true), (fs.client.resolve.topology.enabled,false), (fs.defaultFS,file:///), (fs.df.interval,60000), (fs.du.interval,600000), (fs.ftp.data.connection.mode,ACTIVE_LOCAL_DATA_CONNECTION_MODE), (fs.ftp.host,0.0.0.0), (fs.ftp.host.port,21), (fs.ftp.impl,org.apache.hadoop.fs.ftp.FTPFileSystem), (fs.ftp.timeout,0), (fs.ftp.transfer.mode,BLOCK_TRANSFER_MODE), (fs.getspaceused.jitterMillis,60000), (fs.har.impl.disable.cache,true), (fs.permissions.umask-mode,022), (fs.s3a.accesspoint.required,false), (fs.s3a.assumed.role.credentials.provider,org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider), (fs.s3a.assumed.role.session.duration,30m), (fs.s3a.attempts.maximum,20), (fs.s3a.aws.credentials.provider,
[2025-06-03T07:15:47.548+0000] {subprocess.py:93} INFO -     org.apache.hadoop.fs.s3a.TemporaryAWSCredentialsProvider,
[2025-06-03T07:15:47.548+0000] {subprocess.py:93} INFO -     org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider,
[2025-06-03T07:15:47.548+0000] {subprocess.py:93} INFO -     com.amazonaws.auth.EnvironmentVariableCredentialsProvider,
[2025-06-03T07:15:47.548+0000] {subprocess.py:93} INFO -     org.apache.hadoop.fs.s3a.auth.IAMInstanceCredentialsProvider
[2025-06-03T07:15:47.548+0000] {subprocess.py:93} INFO -   ), (fs.s3a.block.size,32M), (fs.s3a.buffer.dir,${hadoop.tmp.dir}/s3a), (fs.s3a.change.detection.mode,server), (fs.s3a.change.detection.source,etag), (fs.s3a.change.detection.version.required,true), (fs.s3a.committer.abort.pending.uploads,true), (fs.s3a.committer.magic.enabled,true), (fs.s3a.committer.name,file), (fs.s3a.committer.staging.conflict-mode,append), (fs.s3a.committer.staging.tmp.path,tmp/staging), (fs.s3a.committer.staging.unique-filenames,true), (fs.s3a.committer.threads,8), (fs.s3a.connection.establish.timeout,5000), (fs.s3a.connection.maximum,96), (fs.s3a.connection.request.timeout,0), (fs.s3a.connection.ssl.enabled,true), (fs.s3a.connection.timeout,200000), (fs.s3a.downgrade.syncable.exceptions,true), (fs.s3a.endpoint,s3.amazonaws.com), (fs.s3a.etag.checksum.enabled,false), (fs.s3a.executor.capacity,16), (fs.s3a.fast.upload.active.blocks,4), (fs.s3a.fast.upload.buffer,disk), (fs.s3a.impl,org.apache.hadoop.fs.s3a.S3AFileSystem), (fs.s3a.list.version,2), (fs.s3a.max.total.tasks,32), (fs.s3a.metadatastore.authoritative,false), (fs.s3a.metadatastore.fail.on.write.error,true), (fs.s3a.metadatastore.impl,org.apache.hadoop.fs.s3a.s3guard.NullMetadataStore), (fs.s3a.metadatastore.metadata.ttl,15m), (fs.s3a.multiobjectdelete.enable,true), (fs.s3a.multipart.purge,false), (fs.s3a.multipart.purge.age,86400), (fs.s3a.multipart.size,64M), (fs.s3a.multipart.threshold,128M), (fs.s3a.paging.maximum,5000), (fs.s3a.path.style.access,false), (fs.s3a.readahead.range,64K), (fs.s3a.retry.interval,500ms), (fs.s3a.retry.limit,7), (fs.s3a.retry.throttle.interval,100ms), (fs.s3a.retry.throttle.limit,20), (fs.s3a.s3guard.cli.prune.age,86400000), (fs.s3a.s3guard.consistency.retry.interval,2s), (fs.s3a.s3guard.consistency.retry.limit,7), (fs.s3a.s3guard.ddb.background.sleep,25ms), (fs.s3a.s3guard.ddb.max.retries,9), (fs.s3a.s3guard.ddb.table.capacity.read,0), (fs.s3a.s3guard.ddb.table.capacity.write,0), (fs.s3a.s3guard.ddb.table.create,false), (fs.s3a.s3guard.ddb.table.sse.enabled,false), (fs.s3a.s3guard.ddb.throttle.retry.interval,100ms), (fs.s3a.select.enabled,true), (fs.s3a.select.errors.include.sql,false), (fs.s3a.select.input.compression,none), (fs.s3a.select.input.csv.comment.marker,#), (fs.s3a.select.input.csv.field.delimiter,,), (fs.s3a.select.input.csv.header,none), (fs.s3a.select.input.csv.quote.character,"), (fs.s3a.select.input.csv.quote.escape.character,\\), (fs.s3a.select.input.csv.record.delimiter,\n), (fs.s3a.select.output.csv.field.delimiter,,), (fs.s3a.select.output.csv.quote.character,"), (fs.s3a.select.output.csv.quote.escape.character,\\), (fs.s3a.select.output.csv.quote.fields,always), (fs.s3a.select.output.csv.record.delimiter,\n), (fs.s3a.socket.recv.buffer,8192), (fs.s3a.socket.send.buffer,8192), (fs.s3a.ssl.channel.mode,default_jsse), (fs.s3a.threads.keepalivetime,60), (fs.s3a.threads.max,64), (fs.swift.impl,org.apache.hadoop.fs.swift.snative.SwiftNativeFileSystem), (fs.trash.checkpoint.interval,0), (fs.trash.interval,0), (fs.viewfs.overload.scheme.target.abfs.impl,org.apache.hadoop.fs.azurebfs.AzureBlobFileSystem), (fs.viewfs.overload.scheme.target.abfss.impl,org.apache.hadoop.fs.azurebfs.SecureAzureBlobFileSystem), (fs.viewfs.overload.scheme.target.file.impl,org.apache.hadoop.fs.LocalFileSystem), (fs.viewfs.overload.scheme.target.ftp.impl,org.apache.hadoop.fs.ftp.FTPFileSystem), (fs.viewfs.overload.scheme.target.gs.impl,com.google.cloud.hadoop.fs.gcs.GoogleHadoopFS), (fs.viewfs.overload.scheme.target.hdfs.impl,org.apache.hadoop.hdfs.DistributedFileSystem), (fs.viewfs.overload.scheme.target.http.impl,org.apache.hadoop.fs.http.HttpFileSystem), (fs.viewfs.overload.scheme.target.https.impl,org.apache.hadoop.fs.http.HttpsFileSystem), (fs.viewfs.overload.scheme.target.o3fs.impl,org.apache.hadoop.fs.ozone.OzoneFileSystem), (fs.viewfs.overload.scheme.target.ofs.impl,org.apache.hadoop.fs.ozone.RootedOzoneFileSystem), (fs.viewfs.overload.scheme.target.oss.impl,org.apache.hadoop.fs.aliyun.oss.AliyunOSSFileSystem), (fs.viewfs.overload.scheme.target.s3a.impl,org.apache.hadoop.fs.s3a.S3AFileSystem), (fs.viewfs.overload.scheme.target.swebhdfs.impl,org.apache.hadoop.hdfs.web.SWebHdfsFileSystem), (fs.viewfs.overload.scheme.target.swift.impl,org.apache.hadoop.fs.swift.snative.SwiftNativeFileSystem), (fs.viewfs.overload.scheme.target.wasb.impl,org.apache.hadoop.fs.azure.NativeAzureFileSystem), (fs.viewfs.overload.scheme.target.webhdfs.impl,org.apache.hadoop.hdfs.web.WebHdfsFileSystem), (fs.viewfs.rename.strategy,SAME_MOUNTPOINT), (fs.wasb.impl,org.apache.hadoop.fs.azure.NativeAzureFileSystem), (fs.wasbs.impl,org.apache.hadoop.fs.azure.NativeAzureFileSystem$Secure), (ftp.blocksize,67108864), (ftp.bytes-per-checksum,512), (ftp.client-write-packet-size,65536), (ftp.replication,3), (ftp.stream-buffer-size,4096), (ha.failover-controller.active-standby-elector.zk.op.retries,3), (ha.failover-controller.cli-check.rpc-timeout.ms,20000), (ha.failover-controller.graceful-fence.connection.retries,1), (ha.failover-controller.graceful-fence.rpc-timeout.ms,5000), (ha.failover-controller.new-active.rpc-timeout.ms,60000), (ha.health-monitor.check-interval.ms,1000), (ha.health-monitor.connect-retry-interval.ms,1000), (ha.health-monitor.rpc-timeout.ms,45000), (ha.health-monitor.rpc.connect.max.retries,1), (ha.health-monitor.sleep-after-disconnect.ms,1000), (ha.zookeeper.acl,world:anyone:rwcda), (ha.zookeeper.parent-znode,/hadoop-ha), (ha.zookeeper.session-timeout.ms,10000), (hadoop.caller.context.enabled,false), (hadoop.caller.context.max.size,128), (hadoop.caller.context.signature.max.size,40), (hadoop.common.configuration.version,3.0.0), (hadoop.domainname.resolver.impl,org.apache.hadoop.net.DNSDomainNameResolver), (hadoop.http.authentication.kerberos.keytab,${user.home}/hadoop.keytab), (hadoop.http.authentication.kerberos.principal,HTTP/_HOST@LOCALHOST), (hadoop.http.authentication.signature.secret.file,*********(redacted)), (hadoop.http.authentication.simple.anonymous.allowed,true), (hadoop.http.authentication.token.validity,*********(redacted)), (hadoop.http.authentication.type,simple), (hadoop.http.cross-origin.allowed-headers,X-Requested-With,Content-Type,Accept,Origin), (hadoop.http.cross-origin.allowed-methods,GET,POST,HEAD), (hadoop.http.cross-origin.allowed-origins,*), (hadoop.http.cross-origin.enabled,false), (hadoop.http.cross-origin.max-age,1800), (hadoop.http.filter.initializers,org.apache.hadoop.http.lib.StaticUserWebFilter), (hadoop.http.idle_timeout.ms,60000), (hadoop.http.logs.enabled,true), (hadoop.http.sni.host.check.enabled,false), (hadoop.http.staticuser.user,dr.who), (hadoop.jetty.logs.serve.aliases,true), (hadoop.kerberos.keytab.login.autorenewal.enabled,false), (hadoop.kerberos.kinit.command,kinit), (hadoop.kerberos.min.seconds.before.relogin,60), (hadoop.metrics.jvm.use-thread-mxbean,false), (hadoop.prometheus.endpoint.enabled,false), (hadoop.registry.jaas.context,Client), (hadoop.registry.secure,false), (hadoop.registry.system.acls,sasl:yarn@, sasl:mapred@, sasl:hdfs@), (hadoop.registry.zk.connection.timeout.ms,15000), (hadoop.registry.zk.quorum,localhost:2181), (hadoop.registry.zk.retry.ceiling.ms,60000), (hadoop.registry.zk.retry.interval.ms,1000), (hadoop.registry.zk.retry.times,5), (hadoop.registry.zk.root,/registry), (hadoop.registry.zk.session.timeout.ms,60000), (hadoop.rpc.protection,authentication), (hadoop.rpc.socket.factory.class.default,org.apache.hadoop.net.StandardSocketFactory), (hadoop.security.auth_to_local.mechanism,hadoop), (hadoop.security.authentication,simple), (hadoop.security.authorization,false), (hadoop.security.credential.clear-text-fallback,true), (hadoop.security.crypto.buffer.size,8192), (hadoop.security.crypto.cipher.suite,AES/CTR/NoPadding), (hadoop.security.crypto.codec.classes.aes.ctr.nopadding,org.apache.hadoop.crypto.OpensslAesCtrCryptoCodec, org.apache.hadoop.crypto.JceAesCtrCryptoCodec), (hadoop.security.dns.log-slow-lookups.enabled,false), (hadoop.security.dns.log-slow-lookups.threshold.ms,1000), (hadoop.security.group.mapping,org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback), (hadoop.security.group.mapping.ldap.connection.timeout.ms,60000), (hadoop.security.group.mapping.ldap.conversion.rule,none), (hadoop.security.group.mapping.ldap.directory.search.timeout,10000), (hadoop.security.group.mapping.ldap.num.attempts,3), (hadoop.security.group.mapping.ldap.num.attempts.before.failover,3), (hadoop.security.group.mapping.ldap.posix.attr.gid.name,gidNumber), (hadoop.security.group.mapping.ldap.posix.attr.uid.name,uidNumber), (hadoop.security.group.mapping.ldap.read.timeout.ms,60000), (hadoop.security.group.mapping.ldap.search.attr.group.name,cn), (hadoop.security.group.mapping.ldap.search.attr.member,member), (hadoop.security.group.mapping.ldap.search.filter.group,(objectClass=group)), (hadoop.security.group.mapping.ldap.search.filter.user,(&(objectClass=user)(sAMAccountName={0}))), (hadoop.security.group.mapping.ldap.search.group.hierarchy.levels,0), (hadoop.security.group.mapping.ldap.ssl,false), (hadoop.security.group.mapping.providers.combined,true), (hadoop.security.groups.cache.background.reload,false), (hadoop.security.groups.cache.background.reload.threads,3), (hadoop.security.groups.cache.secs,300), (hadoop.security.groups.cache.warn.after.ms,5000), (hadoop.security.groups.negative-cache.secs,30), (hadoop.security.groups.shell.command.timeout,0s), (hadoop.security.instrumentation.requires.admin,false), (hadoop.security.java.secure.random.algorithm,SHA1PRNG), (hadoop.security.key.default.bitlength,128), (hadoop.security.key.default.cipher,AES/CTR/NoPadding), (hadoop.security.kms.client.authentication.retry-count,1), (hadoop.security.kms.client.encrypted.key.cache.expiry,43200000), (hadoop.security.kms.client.encrypted.key.cache.low-watermark,0.3f), (hadoop.security.kms.client.encrypted.key.cache.num.refill.threads,2), (hadoop.security.kms.client.encrypted.key.cache.size,500), (hadoop.security.kms.client.failover.sleep.base.millis,100), (hadoop.security.kms.client.failover.sleep.max.millis,2000), (hadoop.security.kms.client.timeout,60), (hadoop.security.random.device.file.path,/dev/urandom), (hadoop.security.secure.random.impl,org.apache.hadoop.crypto.random.OpensslSecureRandom), (hadoop.security.sensitive-config-keys,*********(redacted)), (hadoop.security.token.service.use_ip,*********(redacted)), (hadoop.security.uid.cache.secs,14400), (hadoop.service.shutdown.timeout,30s), (hadoop.shell.missing.defaultFs.warning,false), (hadoop.shell.safely.delete.limit.num.files,100), (hadoop.ssl.client.conf,ssl-client.xml), (hadoop.ssl.enabled.protocols,TLSv1.2), (hadoop.ssl.hostname.verifier,DEFAULT), (hadoop.ssl.keystores.factory.class,org.apache.hadoop.security.ssl.FileBasedKeyStoresFactory), (hadoop.ssl.require.client.cert,false), (hadoop.ssl.server.conf,ssl-server.xml), (hadoop.system.tags,YARN,HDFS,NAMENODE,DATANODE,REQUIRED,SECURITY,KERBEROS,PERFORMANCE,CLIENT
[2025-06-03T07:15:47.548+0000] {subprocess.py:93} INFO -       ,SERVER,DEBUG,DEPRECATED,COMMON,OPTIONAL), (hadoop.tags.system,YARN,HDFS,NAMENODE,DATANODE,REQUIRED,SECURITY,KERBEROS,PERFORMANCE,CLIENT
[2025-06-03T07:15:47.623+0000] {subprocess.py:93} INFO -       ,SERVER,DEBUG,DEPRECATED,COMMON,OPTIONAL), (hadoop.tmp.dir,/tmp/hadoop-${user.name}), (hadoop.user.group.static.mapping.overrides,dr.who=;), (hadoop.util.hash.type,murmur), (hadoop.workaround.non.threadsafe.getpwuid,true), (hadoop.zk.acl,world:anyone:rwcda), (hadoop.zk.num-retries,1000), (hadoop.zk.retry-interval-ms,1000), (hadoop.zk.timeout-ms,10000), (io.bytes.per.checksum,512), (io.compression.codec.bzip2.library,system-native), (io.erasurecode.codec.rs-legacy.rawcoders,rs-legacy_java), (io.erasurecode.codec.rs.rawcoders,rs_native,rs_